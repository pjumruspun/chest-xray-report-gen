{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2091lines [00:00, 174290.34lines/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caller: c:\\Users\\darkenstardragon\\Documents\\Work\\chest-xray-report-gen\\text_generation\\chexpert.py\n",
      "Creating Chexpert reward module...\n",
      "Using 1 GPUs!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from configs import configs\n",
    "from dataset import ChestXRayCaptionDataset\n",
    "import torch\n",
    "import numpy as np\n",
    "from model import Chexnet\n",
    "from tqdm import tqdm\n",
    "from utils import train_transform, evaluate_transform, quantize_probs\n",
    "from tokenizer import create_tokenizer\n",
    "from test import evaluation_matrix\n",
    "from chexpert import chexpert\n",
    "import time\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_RANDOM_PROJECTION_DATA = False\n",
    "BUILD_CACHED_MAPS = False\n",
    "USE_CACHED_MAPS = True\n",
    "SAVE_PROJECTED = True\n",
    "time_file_path = 'results/inference_time.csv'\n",
    "\n",
    "def filename(k, seed, project_dim):\n",
    "    d = {\n",
    "        'train_x': configs['mimic_dir'] + 'baseline_data/' +  f'train_image_embeddings_{project_dim}_{seed}.npy',\n",
    "        'train_y': configs['mimic_dir'] + 'baseline_data/' +  f'train_captions.npy',\n",
    "        'val_x': configs['mimic_dir'] +'baseline_data/' +  f'val_image_embeddings_{project_dim}_{seed}.npy',\n",
    "        'val_y': configs['mimic_dir'] +'baseline_data/' +  f'val_captions.npy',\n",
    "        'test_x': configs['mimic_dir'] +'baseline_data/' +  f'test_image_embeddings_{project_dim}_{seed}.npy',\n",
    "        'test_y': configs['mimic_dir'] +'baseline_data/' +  f'test_captions.npy',\n",
    "    }\n",
    "\n",
    "    return d[k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2091lines [00:00, 174273.02lines/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded epoch 5 model, val_loss: 0.28202417492866516\n"
     ]
    }
   ],
   "source": [
    "tokenizer = create_tokenizer()\n",
    "checkpoint = torch.load('weights/pretrained_encoder/pretrained_enc_epoch_5_2022-03-08_15-43-47.540586.pth.tar')\n",
    "print(f\"loaded epoch {checkpoint['epoch']+1} model, val_loss: {checkpoint['val_loss']}\")\n",
    "encoder = checkpoint['encoder'].cuda()\n",
    "\n",
    "train_probs_quantized = np.load(configs['mimic_dir'] + 'baseline_data/train_probs_quantized.npy')\n",
    "val_probs_quantized = np.load(configs['mimic_dir'] + 'baseline_data/val_probs_quantized.npy')\n",
    "test_probs_quantized = np.load(configs['mimic_dir'] + 'baseline_data/test_probs_quantized.npy')\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    ChestXRayCaptionDataset('train', transform=train_transform),\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    ChestXRayCaptionDataset('val', transform=evaluate_transform),\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    ChestXRayCaptionDataset('test', transform=evaluate_transform),\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "len_train_loader = 16740\n",
    "len_val_loader = 131\n",
    "len_test_loader = 229"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_embeddings_random(encoder, data_loader, projection_matrix, project_every=2):\n",
    "    # With random projection\n",
    "    encoder.eval()\n",
    "    image_embeddings = []\n",
    "    captions = []\n",
    "    batch = []\n",
    "    with torch.no_grad():\n",
    "        for i, (img, caption, _) in enumerate(tqdm(data_loader)):\n",
    "            img = img.cuda()\n",
    "            encoded_img, _ = encoder(img)\n",
    "            batch.append(encoded_img.cpu())\n",
    "            captions.append(caption.cpu())\n",
    "            if ((i+1) % project_every) == 0 or (i+1) == len(data_loader):\n",
    "                batch = torch.cat(batch).reshape(-1, 1024*8*8).numpy()\n",
    "                batch = np.matmul(batch, projection_matrix)\n",
    "                image_embeddings.append(batch)\n",
    "                batch = []\n",
    "\n",
    "    image_embeddings = np.vstack(image_embeddings)\n",
    "    captions = torch.cat(captions).numpy()\n",
    "    return image_embeddings, captions\n",
    "\n",
    "def generate_image_embeddings_save_every(encoder, data_split, data_loader, save_every=1024):\n",
    "    encoder.eval()\n",
    "    image_embeddings = []\n",
    "    captions = []\n",
    "    file_index = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (img, caption, _) in enumerate(tqdm(data_loader)):\n",
    "            img = img.cuda()\n",
    "            encoded_img, _ = encoder(img)\n",
    "            image_embeddings.append(encoded_img.cpu())\n",
    "            captions.append(caption.cpu())\n",
    "\n",
    "            if ((i+1) % save_every) == 0 or (i+1) == len(data_loader):\n",
    "                # stack\n",
    "                image_embeddings = torch.cat(image_embeddings).reshape(-1, 1024*8*8).numpy()\n",
    "                captions = torch.cat(captions).numpy()\n",
    "\n",
    "                # save\n",
    "                np.save(configs['mimic_dir'] + f'raw_embeddings/{data_split}/feature_maps_{file_index}.npy', image_embeddings)\n",
    "                np.save(configs['mimic_dir'] + f'raw_embeddings/{data_split}/captions_{file_index}.npy', captions)\n",
    "\n",
    "                # clear and update\n",
    "                image_embeddings = []\n",
    "                captions = []\n",
    "                file_index += 1\n",
    "\n",
    "def generate_probs_save_every(encoder, data_split, data_loader, save_every=1024):\n",
    "    encoder.eval()\n",
    "    probs = []\n",
    "    file_index = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (img, _, _) in enumerate(tqdm(data_loader)):\n",
    "            img = img.cuda()\n",
    "            _, prob = encoder(img)\n",
    "            probs.append(prob.cpu())\n",
    "\n",
    "            if ((i+1) % save_every) == 0 or (i+1) == len(data_loader):\n",
    "                # stack\n",
    "                probs = torch.cat(probs).numpy()\n",
    "\n",
    "                # save\n",
    "                np.save(configs['mimic_dir'] + f'raw_embeddings/{data_split}/probs_{file_index}.npy', probs)\n",
    "\n",
    "                # clear and update\n",
    "                probs = []\n",
    "                file_index += 1\n",
    "\n",
    "def random_project(len_data_loader, data_split, projection_matrix, save_every=1024, project_every=256):\n",
    "    n_split = len_data_loader // save_every + 1\n",
    "    print(f\"{n_split=}\")\n",
    "    projected_image_embeddings = []\n",
    "    captions = []\n",
    "    \n",
    "    for file_index in tqdm(range(n_split)):\n",
    "        feat_maps = np.load(configs['mimic_dir'] + f'raw_embeddings/{data_split}/feature_maps_{file_index}.npy')\n",
    "        caps = np.load(configs['mimic_dir'] + f'raw_embeddings/{data_split}/captions_{file_index}.npy')\n",
    "        captions.append(caps)\n",
    "\n",
    "        # project\n",
    "        feat_maps = np.array_split(feat_maps, project_every)\n",
    "        for batch in feat_maps:\n",
    "            proj = np.matmul(batch, projection_matrix)\n",
    "            projected_image_embeddings.append(proj)\n",
    "\n",
    "    projected_image_embeddings = np.vstack(projected_image_embeddings)\n",
    "    captions = np.vstack(captions)\n",
    "    \n",
    "    return projected_image_embeddings, captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_probs_save_every(encoder, 'train', train_loader, save_every=1024)\n",
    "# generate_probs_save_every(encoder, 'val', val_loader, save_every=1024)\n",
    "# generate_probs_save_every(encoder, 'test', test_loader, save_every=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(SEED, RANDOM_PROJECT_DIM, load=False):\n",
    "    \"\"\"\n",
    "    End to end train, val, test projected vectors function\n",
    "    Input:\n",
    "        SEED (int): Seed of the random projection matrix\n",
    "        RANDOM_PROJECT_DIM: Dimension of the random projection matrix\n",
    "    Output:\n",
    "        train_x, train_y, val_x, val_y, test_x, test_y\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Load Cached Vectors\n",
    "    \"\"\"\n",
    "    if load:\n",
    "        \n",
    "        file_suffix = f\"_{RANDOM_PROJECT_DIM}_{SEED}.npy\"\n",
    "        file_prefix = configs['mimic_dir'] + 'baseline_data/'\n",
    "        file_exists = os.path.exists(file_prefix + 'train_image_embeddings' + file_suffix)\n",
    "\n",
    "        if file_exists:\n",
    "            train_image_embeddings = np.load(file_prefix + 'train_image_embeddings' + file_suffix)\n",
    "            train_captions = np.load(file_prefix + 'train_captions.npy')\n",
    "            val_image_embeddings = np.load(file_prefix + 'val_image_embeddings' + file_suffix)\n",
    "            val_captions = np.load(file_prefix + 'val_captions.npy')\n",
    "            test_image_embeddings = np.load(file_prefix + 'test_image_embeddings' + file_suffix)\n",
    "            test_captions = np.load(file_prefix + 'test_captions.npy')\n",
    "            return train_image_embeddings, train_captions, val_image_embeddings, val_captions, test_image_embeddings, test_captions\n",
    "        else:\n",
    "            print(f\"Attempting to load file with seed={SEED} and project_dim={RANDOM_PROJECT_DIM} but doesn't exist\")\n",
    "    \n",
    "    print(f\"Random projecting with {SEED=}, {RANDOM_PROJECT_DIM=}\")\n",
    "    # Create a whole new projection\n",
    "    rng = np.random.RandomState(SEED)\n",
    "    # Gaussian random projection\n",
    "    projection_matrix = rng.normal(0.0, 1/RANDOM_PROJECT_DIM, (65536, RANDOM_PROJECT_DIM))\n",
    "\n",
    "    \"\"\"\n",
    "    Train vectors\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Projecting train vectors...\")\n",
    "\n",
    "    if USE_CACHED_MAPS:\n",
    "        # New method: Predict first, cache them, then project\n",
    "        if BUILD_CACHED_MAPS:\n",
    "            generate_image_embeddings_save_every(encoder, 'train', train_loader, save_every=1024)\n",
    "\n",
    "        train_image_embeddings, train_captions = random_project(len_train_loader, 'train', projection_matrix, save_every=1024, project_every=64)\n",
    "        print(train_image_embeddings.shape)\n",
    "        print(train_captions.shape)\n",
    "        if SAVE_PROJECTED:\n",
    "            np.save(filename('train_x', seed=SEED, project_dim=RANDOM_PROJECT_DIM), train_image_embeddings)\n",
    "            np.save(filename('train_y', seed=SEED, project_dim=RANDOM_PROJECT_DIM), train_captions)\n",
    "    else:\n",
    "        # Old method: Project as we predict\n",
    "        if LOAD_RANDOM_PROJECTION_DATA:\n",
    "            # Use cached projection\n",
    "            # train_image_embeddings = np.load(filename['train_x'])\n",
    "            # train_captions = np.load(filename['train_y'])\n",
    "            print(train_image_embeddings.shape)\n",
    "            print(train_captions.shape)\n",
    "        else:\n",
    "            project_every = 256\n",
    "            train_image_embeddings, train_captions = generate_image_embeddings_random(encoder, train_loader, projection_matrix, project_every=project_every)\n",
    "            print(train_image_embeddings.shape)\n",
    "            print(train_captions.shape)\n",
    "            # np.save(filename['train_x'], train_image_embeddings)\n",
    "            # np.save(filename['train_y'], train_captions)\n",
    "    \n",
    "    \"\"\"\n",
    "    Val & Test vectors\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Projecting val & test vectors...\")\n",
    "\n",
    "    if USE_CACHED_MAPS:\n",
    "        # New method: Predict first, cache them, then project\n",
    "        if BUILD_CACHED_MAPS:\n",
    "            generate_image_embeddings_save_every(encoder, 'val', val_loader, save_every=1024)\n",
    "            generate_image_embeddings_save_every(encoder, 'test', test_loader, save_every=1024)\n",
    "\n",
    "        val_image_embeddings, val_captions = random_project(len_val_loader, 'val', projection_matrix, save_every=1024, project_every=64)\n",
    "        print(val_image_embeddings.shape)\n",
    "        print(val_captions.shape)\n",
    "        if SAVE_PROJECTED:\n",
    "            np.save(filename('val_x', seed=SEED, project_dim=RANDOM_PROJECT_DIM), val_image_embeddings)\n",
    "            np.save(filename('val_y', seed=SEED, project_dim=RANDOM_PROJECT_DIM), val_captions)\n",
    "        test_image_embeddings, test_captions = random_project(len_test_loader, 'test', projection_matrix, save_every=1024, project_every=64)\n",
    "        print(test_image_embeddings.shape)\n",
    "        print(test_captions.shape)\n",
    "        if SAVE_PROJECTED:\n",
    "            np.save(filename('test_x', seed=SEED, project_dim=RANDOM_PROJECT_DIM), test_image_embeddings)\n",
    "            np.save(filename('test_y', seed=SEED, project_dim=RANDOM_PROJECT_DIM), test_captions)\n",
    "\n",
    "    else:\n",
    "        if LOAD_RANDOM_PROJECTION_DATA:\n",
    "            # val_image_embeddings = np.load(filename['val_x'])\n",
    "            # val_captions = np.load(filename['val_y'])\n",
    "            # test_image_embeddings = np.load(filename['test_x'])\n",
    "            # test_captions = np.load(filename['test_y'])\n",
    "            print(val_image_embeddings.shape)\n",
    "            print(val_captions.shape)\n",
    "            print(test_image_embeddings.shape)\n",
    "            print(test_captions.shape)\n",
    "        else:\n",
    "            project_every = 256\n",
    "            val_image_embeddings, val_captions = generate_image_embeddings_random(encoder, val_loader, projection_matrix, project_every=project_every)\n",
    "            print(val_image_embeddings.shape)\n",
    "            print(val_captions.shape)\n",
    "            test_image_embeddings, test_captions = generate_image_embeddings_random(encoder, test_loader, projection_matrix, project_every=project_every)\n",
    "            print(test_image_embeddings.shape)\n",
    "            print(test_captions.shape)\n",
    "            # np.save(filename['val_x'], val_image_embeddings)\n",
    "            # np.save(filename['val_y'], val_captions)\n",
    "            # np.save(filename['test_x'], test_image_embeddings)\n",
    "            # np.save(filename['test_y'], test_captions)\n",
    "    \n",
    "    return train_image_embeddings, train_captions, val_image_embeddings, val_captions, test_image_embeddings, test_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilaritySearch:\n",
    "    def fit(self, xb, yb):\n",
    "        pass\n",
    "\n",
    "    def predict(self, xq):\n",
    "        pass\n",
    "\n",
    "class OneNearestNeighbor(SimilaritySearch):\n",
    "    def __init__(self):\n",
    "        self.yb = None\n",
    "        self.knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "    def fit(self, xb, yb):\n",
    "        indices = [*range(xb.shape[0])]\n",
    "        self.knn.fit(xb.astype(np.float32), indices)\n",
    "        self.yb = yb.astype(np.float32)\n",
    "\n",
    "    def predict(self, xq):\n",
    "        dists, indices = self.knn.kneighbors(xq.astype(np.float32))\n",
    "        yq = np.array([self.yb[i] for i in indices])\n",
    "        yq = yq.reshape(xq.shape[0], self.yb.shape[1])\n",
    "        return yq\n",
    "\n",
    "class FaissFlatIndexL2CPU(SimilaritySearch):\n",
    "    def __init__(self):\n",
    "        self.yb = None\n",
    "        self.index = None\n",
    "\n",
    "    def fit(self, xb, yb):\n",
    "        dim = xb.shape[1]\n",
    "        self.index = faiss.IndexFlatL2(dim)\n",
    "        self.index.add(xb.astype(np.float32))\n",
    "        self.yb = yb.astype(np.float32)\n",
    "\n",
    "    def predict(self, xq):\n",
    "        dists, indices = self.index.search(xq.astype(np.float32), 1)\n",
    "        yq = np.array([self.yb[i] for i in indices])\n",
    "        yq = yq.reshape(xq.shape[0], self.yb.shape[1])\n",
    "        return yq\n",
    "\n",
    "class FaissFlatIndexL2GPU(SimilaritySearch):\n",
    "    def __init__(self):\n",
    "        self.res = faiss.StandardGpuResources()\n",
    "        self.yb = None\n",
    "        self.gpu_index = None\n",
    "\n",
    "    def fit(self, xb, yb):\n",
    "        dim = xb.shape[1]\n",
    "        self.gpu_index = faiss.index_cpu_to_gpu(self.res, 0, faiss.IndexFlatL2(dim))\n",
    "        self.gpu_index.add(xb.astype(np.float32))\n",
    "        self.yb = yb.astype(np.float32)\n",
    "\n",
    "    def predict(self, xq):\n",
    "        dists, indices = self.gpu_index.search(xq.astype(np.float32), 1)\n",
    "        yq = np.array([self.yb[i] for i in indices])\n",
    "        yq = yq.reshape(xq.shape[0], self.yb.shape[1])\n",
    "        return yq\n",
    "\n",
    "class FaissHNSW32(SimilaritySearch):\n",
    "    def __init__(self):\n",
    "        self.yb = None\n",
    "        self.index = None\n",
    "\n",
    "    def fit(self, xb, yb):\n",
    "        dim = xb.shape[1]\n",
    "        self.index = faiss.IndexHNSWFlat(dim, 32)\n",
    "        self.index.add(xb.astype(np.float32))\n",
    "        self.yb = yb.astype(np.float32)\n",
    "\n",
    "    def predict(self, xq):\n",
    "        dists, indices = self.index.search(xq.astype(np.float32), 1)\n",
    "        yq = np.array([self.yb[i] for i in indices])\n",
    "        yq = yq.reshape(xq.shape[0], self.yb.shape[1])\n",
    "        return yq\n",
    "\n",
    "class FaissLSH32(SimilaritySearch):\n",
    "    def __init__(self):\n",
    "        self.yb = None\n",
    "        self.index = None\n",
    "\n",
    "    def fit(self, xb, yb):\n",
    "        dim = xb.shape[1]\n",
    "        self.index = faiss.IndexLSH(dim, 32)\n",
    "        self.index.add(xb.astype(np.float32))\n",
    "        self.yb = yb.astype(np.float32)\n",
    "\n",
    "    def predict(self, xq):\n",
    "        dists, indices = self.index.search(xq.astype(np.float32), 1)\n",
    "        yq = np.array([self.yb[i] for i in indices])\n",
    "        yq = yq.reshape(xq.shape[0], self.yb.shape[1])\n",
    "        return yq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilaritySearchCoarse2Fine(SimilaritySearch):\n",
    "    def assign_labels(self, train_labels):\n",
    "        self.train_labels = train_labels\n",
    "\n",
    "    def assign_encoder(self, encoder):\n",
    "        self.encoder = encoder\n",
    "\n",
    "class OneNearestNeighborCoarse2Fine(SimilaritySearchCoarse2Fine):\n",
    "    def __init__(self):\n",
    "        # Dict label -> feature maps\n",
    "        self.map = defaultdict(lambda: [])\n",
    "        self.reports = defaultdict(lambda: [])\n",
    "        self.knns = dict()\n",
    "        self.assign_labels(train_probs_quantized)\n",
    "    \n",
    "    def fit(self, xb, yb):\n",
    "        binary_strings = [''.join(label.astype(str)) for label in self.train_labels]\n",
    "        # for label, feat_maps in tqdm(zip(binary_strings, xb), total=len(binary_strings)):\n",
    "        for i in range(len(binary_strings)):\n",
    "            label = binary_strings[i]\n",
    "            feat_maps = xb[i]\n",
    "            report = yb[i]\n",
    "            self.map[label].append(feat_maps)\n",
    "            self.reports[label].append(report)\n",
    "\n",
    "        for label, feat_maps_list in self.map.items():\n",
    "            indices = [*range(len(feat_maps_list))]\n",
    "            self.knns[label] = KNeighborsClassifier(n_neighbors=1)\n",
    "            self.knns[label].fit(np.array(feat_maps_list).astype(np.float32), indices)\n",
    "\n",
    "    def predict(self, xq, x_image):\n",
    "        _, probs = encoder(x_image)\n",
    "        labels = quantize_probs(probs.detach().cpu().numpy())\n",
    "        labels = [''.join(label.astype(str)) for label in labels]\n",
    "        results = []\n",
    "        no_label_count = 0\n",
    "        for label, feat_map in zip(labels, xq):\n",
    "            # Might not found exact label in training\n",
    "            # Might need to search in near edit distance\n",
    "            if label in self.knns.keys():\n",
    "                dists, index = self.knns[label].kneighbors(feat_map.astype(np.float32).reshape(1, -1))\n",
    "                yq = np.array(self.reports[label][index[0][0]]).reshape(-1)\n",
    "            else:\n",
    "                # Handle no label\n",
    "                similar_labels_list = self.get_similar_binaries(label)\n",
    "                similar_feature_maps = []\n",
    "                similar_reports = []\n",
    "                for sim_label in similar_labels_list:\n",
    "                    if sim_label in self.map.keys():\n",
    "                        # Need to make sure the sim label exists\n",
    "                        similar_feature_maps.extend(self.map[sim_label])\n",
    "                        similar_reports.extend(self.reports[sim_label])\n",
    "                \n",
    "                # Create temp knn\n",
    "                temp_knn = KNeighborsClassifier(n_neighbors=1)\n",
    "                indices = [*range(len(similar_feature_maps))]\n",
    "                temp_knn.fit(similar_feature_maps, indices)\n",
    "                dists, index = temp_knn.kneighbors(feat_map.astype(np.float32).reshape(1, -1))\n",
    "                yq = np.array(similar_reports[index[0][0]]).reshape(-1)\n",
    "                no_label_count += 1 # For monitoring purpose\n",
    "\n",
    "            results.append(yq)\n",
    "\n",
    "        # if no_label_count > 0:\n",
    "        #     print(f\"No label count: {no_label_count}\")\n",
    "        return np.array(results)\n",
    "\n",
    "    def get_similar_binaries(self, binary_str: str):\n",
    "        \"\"\"\n",
    "        Returns a list of similar binary string with edit distance = 1\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        for i in range(len(binary_str)):\n",
    "            res.append(binary_str[:i] + str(int(not(bool(int(binary_str[i]))))) + binary_str[i+1:])\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, embeddings, decode=False, batch_size=64, image_loader=None):\n",
    "    captions = []\n",
    "    total_time = 0.0\n",
    "\n",
    "    assert isinstance(model, SimilaritySearchCoarse2Fine) == (image_loader != None), (\n",
    "        f\"isinstance={isinstance(model, SimilaritySearchCoarse2Fine)} but image_loader != None is {image_loader != None}\"\n",
    "    )\n",
    "\n",
    "    if isinstance(model, SimilaritySearchCoarse2Fine) and image_loader != None:\n",
    "        print(f\"forced batch size: {image_loader.batch_size}\")\n",
    "        data_loader = DataLoader(\n",
    "            embeddings,\n",
    "            batch_size=image_loader.batch_size,\n",
    "            num_workers=0,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "        assert len(data_loader) == len(image_loader), (\n",
    "            f\"{len(data_loader)=}, {len(image_loader)=}\"\n",
    "        )\n",
    "\n",
    "        for j, (batch, (image, _, _)) in enumerate(tqdm(zip(data_loader, image_loader), total=len(data_loader))):\n",
    "            start = time.time()\n",
    "            yq = model.predict(batch.numpy(), image.cuda())\n",
    "            total_time += time.time() - start\n",
    "            captions.extend(yq)\n",
    "    else:\n",
    "        data_loader = DataLoader(\n",
    "            embeddings,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=0,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "        for j, batch in enumerate(tqdm(data_loader)):\n",
    "            start = time.time()\n",
    "            yq = model.predict(batch.numpy())\n",
    "            total_time += time.time() - start\n",
    "            captions.extend(yq)\n",
    "\n",
    "    captions = np.array(captions).reshape(embeddings.shape[0], -1)\n",
    "    if decode:\n",
    "        captions = tokenizer.decode(captions)\n",
    "    return captions, total_time\n",
    "\n",
    "def evaluate(true_captions, pred_captions, batch_size):\n",
    "    true_df = []\n",
    "    pred_df = []\n",
    "    print(true_captions.shape[0], pred_captions.shape[0])\n",
    "    true_loader = DataLoader(\n",
    "        true_captions, \n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    pred_loader = DataLoader(\n",
    "        pred_captions, \n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    for t in tqdm(true_loader):\n",
    "        labels = chexpert(t, tokenizer)\n",
    "        true_df.append(labels)\n",
    "\n",
    "    for p in tqdm(pred_loader):\n",
    "        labels = chexpert(p, tokenizer)\n",
    "        pred_df.append(labels)\n",
    "    \n",
    "    true_df = pd.concat(true_df).reset_index(drop=True)\n",
    "    pred_df = pd.concat(pred_df).reset_index(drop=True)\n",
    "    return evaluation_matrix(true_df, pred_df)\n",
    "\n",
    "def write_time_file(model, project_dim, seed, val_time, test_time):\n",
    "    with open(time_file_path, 'a') as f:\n",
    "        model_type = type(model).__name__\n",
    "        f.write(f\"{model_type},{pd.Timestamp.now()},{project_dim},{seed},{val_time},{test_time}\\n\")\n",
    "\n",
    "def evaluate_all(model, val_image_embeddings, val_captions, test_image_embeddings, test_captions, seed, project_dim):\n",
    "    if isinstance(model, SimilaritySearchCoarse2Fine):\n",
    "        predicted_reports, val_time = predict(model, val_image_embeddings, batch_size=1024, image_loader=val_loader)\n",
    "    else:\n",
    "        predicted_reports, val_time = predict(model, val_image_embeddings, batch_size=1024)\n",
    "    print(f\"Time taken to predict val: {val_time:.3f} seconds\")\n",
    "    val_eval_matrix = evaluate(val_captions, predicted_reports, batch_size=8)\n",
    "    val_eval_matrix.to_csv(\n",
    "        f'results/{type(model).__name__}_val_results_{project_dim}_{seed}.csv', index=False\n",
    "    )\n",
    "    print(val_eval_matrix)\n",
    "\n",
    "    if isinstance(model, SimilaritySearchCoarse2Fine):\n",
    "        predicted_reports, test_time = predict(model, test_image_embeddings, batch_size=1024, image_loader=test_loader)\n",
    "    else:\n",
    "        predicted_reports, test_time = predict(model, test_image_embeddings, batch_size=1024)\n",
    "    print(f\"Time taken to predict test: {test_time:.3f} seconds\")\n",
    "    test_eval_matrix = evaluate(test_captions, predicted_reports, batch_size=8)\n",
    "    test_eval_matrix.to_csv(\n",
    "        f'results/{type(model).__name__}_test_results_{project_dim}_{seed}.csv', index=False\n",
    "    )\n",
    "    print(test_eval_matrix)\n",
    "\n",
    "    write_time_file(model, project_dim, seed, val_time, test_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e2e_benchmark(model_class, seed, project_dim, load=False):\n",
    "    \"\"\"\n",
    "    Perform vector acquisition, 1-NN, and evaluate on val and test set, and save results into files\n",
    "    \"\"\"\n",
    "\n",
    "    # Get vector\n",
    "    train_image_embeddings, train_captions, val_image_embeddings, val_captions, test_image_embeddings, test_captions = get_vectors(seed, project_dim, load=load)\n",
    "\n",
    "    # Model selection\n",
    "    model = model_class()\n",
    "    if isinstance(model, SimilaritySearchCoarse2Fine):\n",
    "        model.assign_encoder(encoder)\n",
    "\n",
    "    # Train\n",
    "    model.fit(train_image_embeddings, train_captions)\n",
    "\n",
    "    # Evaluate\n",
    "    evaluate_all(model, val_image_embeddings, val_captions, test_image_embeddings, test_captions, seed, project_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [OneNearestNeighborCoarse2Fine]\n",
    "seeds = [0, 1000, 2000, 3000, 4000]\n",
    "dims = [128, 256, 512, 1024, 2048, 4096, 8192]\n",
    "\n",
    "for model_class in models:\n",
    "    for dim in dims:\n",
    "        for seed in seeds:\n",
    "            path_to_check = f'results/{model_class.__name__}_test_results_{dim}_{seed}.csv'\n",
    "            exist = os.path.exists(path_to_check)\n",
    "            if not exist:\n",
    "                print(model_class.__name__, dim, seed)\n",
    "                e2e_benchmark(model_class, seed=seed, project_dim=dim, load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chexperify(captions, batch_size):\n",
    "    \"\"\"\n",
    "    Returns a dataframe with labels and captions alongside\n",
    "    Example usage:\n",
    "\n",
    "        true_df = chexperify(test_captions, batch_size=12)\n",
    "        pred_df = chexperify(test_predicted_reports, batch_size=12)\n",
    "\n",
    "    \"\"\"\n",
    "    df = []\n",
    "    data_loader = DataLoader(\n",
    "        captions, \n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    for batch in tqdm(data_loader):\n",
    "        labels = chexpert(batch, tokenizer)\n",
    "        df.append(labels)\n",
    "\n",
    "\n",
    "    df = pd.concat(df).reset_index(drop=True)\n",
    "    df['captions'] = tokenizer.decode(captions)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test from remote run on server\n",
    "\n",
    "Requirements: `predicted_val_captions.npy` and `predicted_test_captions.npy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174/174 [00:52<00:00,  3.29it/s]\n",
      "100%|██████████| 174/174 [01:05<00:00,  2.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <td>0.729483</td>\n",
       "      <td>0.658436</td>\n",
       "      <td>0.692141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <td>0.657244</td>\n",
       "      <td>0.613861</td>\n",
       "      <td>0.634812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lung Opacity</th>\n",
       "      <td>0.744152</td>\n",
       "      <td>0.712885</td>\n",
       "      <td>0.728183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lung Lesion</th>\n",
       "      <td>0.266355</td>\n",
       "      <td>0.360759</td>\n",
       "      <td>0.306452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edema</th>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.550562</td>\n",
       "      <td>0.575793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consolidation</th>\n",
       "      <td>0.620123</td>\n",
       "      <td>0.683258</td>\n",
       "      <td>0.650161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pneumonia</th>\n",
       "      <td>0.438119</td>\n",
       "      <td>0.517544</td>\n",
       "      <td>0.474531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atelectasis</th>\n",
       "      <td>0.624299</td>\n",
       "      <td>0.660079</td>\n",
       "      <td>0.641691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pneumothorax</th>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.158940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <td>0.640426</td>\n",
       "      <td>0.650108</td>\n",
       "      <td>0.645230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pleural Other</th>\n",
       "      <td>0.422819</td>\n",
       "      <td>0.480916</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fracture</th>\n",
       "      <td>0.555738</td>\n",
       "      <td>0.559406</td>\n",
       "      <td>0.557566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Devices</th>\n",
       "      <td>0.632135</td>\n",
       "      <td>0.688940</td>\n",
       "      <td>0.659316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Finding</th>\n",
       "      <td>0.822695</td>\n",
       "      <td>0.849817</td>\n",
       "      <td>0.836036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macro</th>\n",
       "      <td>0.564656</td>\n",
       "      <td>0.582714</td>\n",
       "      <td>0.572204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro</th>\n",
       "      <td>0.634371</td>\n",
       "      <td>0.649143</td>\n",
       "      <td>0.641672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                       Recall  Precision        F1\n",
       "Enlarged Cardiomediastinum  0.729483   0.658436  0.692141\n",
       "Cardiomegaly                0.657244   0.613861  0.634812\n",
       "Lung Opacity                0.744152   0.712885  0.728183\n",
       "Lung Lesion                 0.266355   0.360759  0.306452\n",
       "Edema                       0.603448   0.550562  0.575793\n",
       "Consolidation               0.620123   0.683258  0.650161\n",
       "Pneumonia                   0.438119   0.517544  0.474531\n",
       "Atelectasis                 0.624299   0.660079  0.641691\n",
       "Pneumothorax                0.148148   0.171429  0.158940\n",
       "Pleural Effusion            0.640426   0.650108  0.645230\n",
       "Pleural Other               0.422819   0.480916  0.450000\n",
       "Fracture                    0.555738   0.559406  0.557566\n",
       "Support Devices             0.632135   0.688940  0.659316\n",
       "No Finding                  0.822695   0.849817  0.836036\n",
       "Macro                       0.564656   0.582714  0.572204\n",
       "Micro                       0.634371   0.649143  0.641672"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_captions = np.load('remote_server/predicted_val_captions.npy')\n",
    "until = pred_captions.shape[0]\n",
    "true_captions = np.load('mimic_cxr/raw_embeddings/val/captions_0.npy')[:until]\n",
    "evaluate(true_captions, pred_captions, batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:15<00:00,  2.72it/s]\n",
      "100%|██████████| 42/42 [00:09<00:00,  4.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <td>0.746429</td>\n",
       "      <td>0.741135</td>\n",
       "      <td>0.743772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <td>0.691304</td>\n",
       "      <td>0.679487</td>\n",
       "      <td>0.685345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lung Opacity</th>\n",
       "      <td>0.784722</td>\n",
       "      <td>0.733766</td>\n",
       "      <td>0.758389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lung Lesion</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.367647</td>\n",
       "      <td>0.259067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edema</th>\n",
       "      <td>0.565934</td>\n",
       "      <td>0.559783</td>\n",
       "      <td>0.562842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consolidation</th>\n",
       "      <td>0.480952</td>\n",
       "      <td>0.554945</td>\n",
       "      <td>0.515306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pneumonia</th>\n",
       "      <td>0.413408</td>\n",
       "      <td>0.544118</td>\n",
       "      <td>0.469841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atelectasis</th>\n",
       "      <td>0.610465</td>\n",
       "      <td>0.486111</td>\n",
       "      <td>0.541237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pneumothorax</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <td>0.527607</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>0.529231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pleural Other</th>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.614754</td>\n",
       "      <td>0.531915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fracture</th>\n",
       "      <td>0.598086</td>\n",
       "      <td>0.606796</td>\n",
       "      <td>0.602410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Devices</th>\n",
       "      <td>0.597087</td>\n",
       "      <td>0.768750</td>\n",
       "      <td>0.672131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Finding</th>\n",
       "      <td>0.581197</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.541833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macro</th>\n",
       "      <td>0.524098</td>\n",
       "      <td>0.559891</td>\n",
       "      <td>0.536325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro</th>\n",
       "      <td>0.581012</td>\n",
       "      <td>0.615033</td>\n",
       "      <td>0.597539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                       Recall  Precision        F1\n",
       "Enlarged Cardiomediastinum  0.746429   0.741135  0.743772\n",
       "Cardiomegaly                0.691304   0.679487  0.685345\n",
       "Lung Opacity                0.784722   0.733766  0.758389\n",
       "Lung Lesion                 0.200000   0.367647  0.259067\n",
       "Edema                       0.565934   0.559783  0.562842\n",
       "Consolidation               0.480952   0.554945  0.515306\n",
       "Pneumonia                   0.413408   0.544118  0.469841\n",
       "Atelectasis                 0.610465   0.486111  0.541237\n",
       "Pneumothorax                0.071429   0.142857  0.095238\n",
       "Pleural Effusion            0.527607   0.530864  0.529231\n",
       "Pleural Other               0.468750   0.614754  0.531915\n",
       "Fracture                    0.598086   0.606796  0.602410\n",
       "Support Devices             0.597087   0.768750  0.672131\n",
       "No Finding                  0.581197   0.507463  0.541833\n",
       "Macro                       0.524098   0.559891  0.536325\n",
       "Micro                       0.581012   0.615033  0.597539"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_captions = np.load('remote_server/predicted_test_captions.npy')\n",
    "until = pred_captions.shape[0]\n",
    "true_captions = np.load('mimic_cxr/raw_embeddings/test/captions_0.npy')[:until]\n",
    "evaluate(true_captions, pred_captions, batch_size=12)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5b2b1eb0b4180dccfbf3e31c6f887b3086317eead5a7f5406a6958b92b74dfc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('research_rl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
