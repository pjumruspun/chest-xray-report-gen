{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2091lines [00:00, 174710.45lines/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caller: c:\\Users\\darkenstardragon\\Documents\\Work\\chest-xray-report-gen\\text_generation\\chexpert.py\n",
      "Creating Chexpert reward module...\n",
      "Using 1 GPUs!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from configs import configs\n",
    "from dataset import ChestXRayCaptionDataset\n",
    "import torch\n",
    "import numpy as np\n",
    "from model import Chexnet\n",
    "from tqdm import tqdm\n",
    "from utils import train_transform, evaluate_transform\n",
    "from tokenizer import create_tokenizer\n",
    "from test import evaluation_matrix\n",
    "from chexpert import chexpert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_RANDOM_PROJECTION_DATA = False\n",
    "# RANDOM_PROJECT_DIM = 128\n",
    "BUILD_CACHED_MAPS = False\n",
    "USE_CACHED_MAPS = True\n",
    "# SEED = 0\n",
    "\n",
    "# filename = {\n",
    "#     'train_x': configs['mimic_dir'] + 'baseline_data/' +  f'train_image_embeddings_{RANDOM_PROJECT_DIM}_{SEED}.npy',\n",
    "#     'train_y': configs['mimic_dir'] + 'baseline_data/' +  f'train_captions_{RANDOM_PROJECT_DIM}_{SEED}.npy',\n",
    "#     'val_x': configs['mimic_dir'] +'baseline_data/' +  f'val_image_embeddings_{RANDOM_PROJECT_DIM}_{SEED}.npy',\n",
    "#     'val_y': configs['mimic_dir'] +'baseline_data/' +  f'val_captions_{RANDOM_PROJECT_DIM}_{SEED}.npy',\n",
    "#     'test_x': configs['mimic_dir'] +'baseline_data/' +  f'test_image_embeddings_{RANDOM_PROJECT_DIM}_{SEED}.npy',\n",
    "#     'test_y': configs['mimic_dir'] +'baseline_data/' +  f'test_captions_{RANDOM_PROJECT_DIM}_{SEED}.npy',\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2091lines [00:00, 174717.41lines/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded epoch 5 model, val_loss: 0.28202417492866516\n"
     ]
    }
   ],
   "source": [
    "tokenizer = create_tokenizer()\n",
    "checkpoint = torch.load('weights/pretrained_encoder/pretrained_enc_epoch_5_2022-03-08_15-43-47.540586.pth.tar')\n",
    "print(f\"loaded epoch {checkpoint['epoch']+1} model, val_loss: {checkpoint['val_loss']}\")\n",
    "encoder = checkpoint['encoder'].cuda()\n",
    "train_loader = DataLoader(\n",
    "    ChestXRayCaptionDataset('train', transform=train_transform),\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    ChestXRayCaptionDataset('val', transform=evaluate_transform),\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    ChestXRayCaptionDataset('test', transform=evaluate_transform),\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_embeddings_random(encoder, data_loader, projection_matrix, project_every=2):\n",
    "    # With random projection\n",
    "    encoder.eval()\n",
    "    image_embeddings = []\n",
    "    captions = []\n",
    "    batch = []\n",
    "    with torch.no_grad():\n",
    "        for i, (img, caption, _) in enumerate(tqdm(data_loader)):\n",
    "            img = img.cuda()\n",
    "            encoded_img, _ = encoder(img)\n",
    "            batch.append(encoded_img.cpu())\n",
    "            captions.append(caption.cpu())\n",
    "            if ((i+1) % project_every) == 0 or (i+1) == len(data_loader):\n",
    "                batch = torch.cat(batch).reshape(-1, 1024*8*8).numpy()\n",
    "                batch = np.matmul(batch, projection_matrix)\n",
    "                image_embeddings.append(batch)\n",
    "                batch = []\n",
    "\n",
    "    image_embeddings = np.vstack(image_embeddings)\n",
    "    captions = torch.cat(captions).numpy()\n",
    "    return image_embeddings, captions\n",
    "\n",
    "def generate_image_embeddings_save_every(encoder, data_split, data_loader, save_every=1024):\n",
    "    encoder.eval()\n",
    "    image_embeddings = []\n",
    "    captions = []\n",
    "    file_index = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (img, caption, _) in enumerate(tqdm(data_loader)):\n",
    "            img = img.cuda()\n",
    "            encoded_img, _ = encoder(img)\n",
    "            image_embeddings.append(encoded_img.cpu())\n",
    "            captions.append(caption.cpu())\n",
    "\n",
    "            if ((i+1) % save_every) == 0 or (i+1) == len(data_loader):\n",
    "                # stack\n",
    "                image_embeddings = torch.cat(image_embeddings).reshape(-1, 1024*8*8).numpy()\n",
    "                captions = torch.cat(captions).numpy()\n",
    "\n",
    "                # save\n",
    "                np.save(configs['mimic_dir'] + f'raw_embeddings/{data_split}/feature_maps_{file_index}.npy', image_embeddings)\n",
    "                np.save(configs['mimic_dir'] + f'raw_embeddings/{data_split}/captions_{file_index}.npy', captions)\n",
    "\n",
    "                # clear and update\n",
    "                image_embeddings = []\n",
    "                captions = []\n",
    "                file_index += 1\n",
    "\n",
    "def random_project(data_loader, data_split, projection_matrix, save_every=1024, project_every=256):\n",
    "    n_split = len(data_loader) // save_every + 1\n",
    "    print(f\"{n_split=}\")\n",
    "    projected_image_embeddings = []\n",
    "    captions = []\n",
    "    \n",
    "    for file_index in tqdm(range(n_split)):\n",
    "        feat_maps = np.load(configs['mimic_dir'] + f'raw_embeddings/{data_split}/feature_maps_{file_index}.npy')\n",
    "        caps = np.load(configs['mimic_dir'] + f'raw_embeddings/{data_split}/captions_{file_index}.npy')\n",
    "        captions.append(caps)\n",
    "\n",
    "        # project\n",
    "        feat_maps = np.array_split(feat_maps, project_every)\n",
    "        for batch in feat_maps:\n",
    "            proj = np.matmul(batch, projection_matrix)\n",
    "            projected_image_embeddings.append(proj)\n",
    "\n",
    "    projected_image_embeddings = np.vstack(projected_image_embeddings)\n",
    "    captions = np.vstack(captions)\n",
    "    \n",
    "    return projected_image_embeddings, captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(SEED, RANDOM_PROJECT_DIM, load=False):\n",
    "    \"\"\"\n",
    "    End to end train, val, test projected vectors function\n",
    "    Input:\n",
    "        SEED (int): Seed of the random projection matrix\n",
    "        RANDOM_PROJECT_DIM: Dimension of the random projection matrix\n",
    "    Output:\n",
    "        train_x, train_y, val_x, val_y, test_x, test_y\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Load Cached Vectors\n",
    "    \"\"\"\n",
    "    if load:\n",
    "        file_suffix = f\"_{RANDOM_PROJECT_DIM}_{SEED}.npy\"\n",
    "        file_prefix = configs['mimic_dir'] + 'baseline_data/'\n",
    "        train_image_embeddings = np.load(file_prefix + 'train_image_embeddings' + file_suffix)\n",
    "        train_captions = np.load(file_prefix + 'train_captions' + file_suffix)\n",
    "        val_image_embeddings = np.load(file_prefix + 'val_image_embeddings' + file_suffix)\n",
    "        val_captions = np.load(file_prefix + 'val_captions' + file_suffix)\n",
    "        test_image_embeddings = np.load(file_prefix + 'test_image_embeddings' + file_suffix)\n",
    "        test_captions = np.load(file_prefix + 'test_captions' + file_suffix)\n",
    "        return train_image_embeddings, train_captions, val_image_embeddings, val_captions, test_image_embeddings, test_captions\n",
    "    \n",
    "    print(f\"Random projecting with {SEED=}, {RANDOM_PROJECT_DIM=}\")\n",
    "    # Create a whole new projection\n",
    "    rng = np.random.RandomState(SEED)\n",
    "    # Gaussian random projection\n",
    "    projection_matrix = rng.normal(0.0, 1/RANDOM_PROJECT_DIM, (65536, RANDOM_PROJECT_DIM))\n",
    "\n",
    "    \"\"\"\n",
    "    Train vectors\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Projecting train vectors...\")\n",
    "\n",
    "    if USE_CACHED_MAPS:\n",
    "        # New method: Predict first, cache them, then project\n",
    "        if BUILD_CACHED_MAPS:\n",
    "            generate_image_embeddings_save_every(encoder, 'train', train_loader, save_every=1024)\n",
    "\n",
    "        train_image_embeddings, train_captions = random_project(train_loader, 'train', projection_matrix, save_every=1024, project_every=64)\n",
    "        print(train_image_embeddings.shape)\n",
    "        print(train_captions.shape)\n",
    "        # np.save(filename['train_x'], train_image_embeddings)\n",
    "        # np.save(filename['train_y'], train_captions)\n",
    "    else:\n",
    "        # Old method: Project as we predict\n",
    "        if LOAD_RANDOM_PROJECTION_DATA:\n",
    "            # Use cached projection\n",
    "            # train_image_embeddings = np.load(filename['train_x'])\n",
    "            # train_captions = np.load(filename['train_y'])\n",
    "            print(train_image_embeddings.shape)\n",
    "            print(train_captions.shape)\n",
    "        else:\n",
    "            project_every = 256\n",
    "            train_image_embeddings, train_captions = generate_image_embeddings_random(encoder, train_loader, projection_matrix, project_every=project_every)\n",
    "            print(train_image_embeddings.shape)\n",
    "            print(train_captions.shape)\n",
    "            # np.save(filename['train_x'], train_image_embeddings)\n",
    "            # np.save(filename['train_y'], train_captions)\n",
    "    \n",
    "    \"\"\"\n",
    "    Val & Test vectors\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Projecting val & test vectors...\")\n",
    "\n",
    "    if USE_CACHED_MAPS:\n",
    "        # New method: Predict first, cache them, then project\n",
    "        if BUILD_CACHED_MAPS:\n",
    "            generate_image_embeddings_save_every(encoder, 'val', val_loader, save_every=1024)\n",
    "            generate_image_embeddings_save_every(encoder, 'test', test_loader, save_every=1024)\n",
    "\n",
    "        val_image_embeddings, val_captions = random_project(val_loader, 'val', projection_matrix, save_every=1024, project_every=64)\n",
    "        print(val_image_embeddings.shape)\n",
    "        print(val_captions.shape)\n",
    "        # np.save(filename['val_x'], val_image_embeddings)\n",
    "        # np.save(filename['val_y'], val_captions)\n",
    "        test_image_embeddings, test_captions = random_project(test_loader, 'test', projection_matrix, save_every=1024, project_every=64)\n",
    "        print(test_image_embeddings.shape)\n",
    "        print(test_captions.shape)\n",
    "        # np.save(filename['test_x'], test_image_embeddings)\n",
    "        # np.save(filename['test_y'], test_captions)\n",
    "\n",
    "    else:\n",
    "        if LOAD_RANDOM_PROJECTION_DATA:\n",
    "            # val_image_embeddings = np.load(filename['val_x'])\n",
    "            # val_captions = np.load(filename['val_y'])\n",
    "            # test_image_embeddings = np.load(filename['test_x'])\n",
    "            # test_captions = np.load(filename['test_y'])\n",
    "            print(val_image_embeddings.shape)\n",
    "            print(val_captions.shape)\n",
    "            print(test_image_embeddings.shape)\n",
    "            print(test_captions.shape)\n",
    "        else:\n",
    "            project_every = 256\n",
    "            val_image_embeddings, val_captions = generate_image_embeddings_random(encoder, val_loader, projection_matrix, project_every=project_every)\n",
    "            print(val_image_embeddings.shape)\n",
    "            print(val_captions.shape)\n",
    "            test_image_embeddings, test_captions = generate_image_embeddings_random(encoder, test_loader, projection_matrix, project_every=project_every)\n",
    "            print(test_image_embeddings.shape)\n",
    "            print(test_captions.shape)\n",
    "            # np.save(filename['val_x'], val_image_embeddings)\n",
    "            # np.save(filename['val_y'], val_captions)\n",
    "            # np.save(filename['test_x'], test_image_embeddings)\n",
    "            # np.save(filename['test_y'], test_captions)\n",
    "    \n",
    "    return train_image_embeddings, train_captions, val_image_embeddings, val_captions, test_image_embeddings, test_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(embeddings, train_captions, one_nn, decode=False, batch_size=64):\n",
    "    captions = []\n",
    "    data_loader = DataLoader(\n",
    "        embeddings,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    for j, batch in enumerate(tqdm(data_loader)):\n",
    "        dists, indices = one_nn.kneighbors(batch)\n",
    "        captions.extend([train_captions[i] for i in indices])\n",
    "    captions = np.array(captions).reshape(embeddings.shape[0], -1)\n",
    "    if decode:\n",
    "        captions = tokenizer.decode(captions)\n",
    "    return captions\n",
    "\n",
    "def evaluate(true_captions, pred_captions, batch_size):\n",
    "    true_df = []\n",
    "    pred_df = []\n",
    "\n",
    "    true_loader = DataLoader(\n",
    "        true_captions, \n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    pred_loader = DataLoader(\n",
    "        pred_captions, \n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    for t in tqdm(true_loader):\n",
    "        labels = chexpert(t, tokenizer)\n",
    "        true_df.append(labels)\n",
    "\n",
    "    for p in tqdm(pred_loader):\n",
    "        labels = chexpert(p, tokenizer)\n",
    "        pred_df.append(labels)\n",
    "    \n",
    "    true_df = pd.concat(true_df).reset_index(drop=True)\n",
    "    pred_df = pd.concat(pred_df).reset_index(drop=True)\n",
    "    return evaluation_matrix(true_df, pred_df)\n",
    "\n",
    "def evaluate_all(one_nn, train_captions, val_image_embeddings, val_captions, test_image_embeddings, test_captions, seed, project_dim):\n",
    "    predicted_reports = predict(val_image_embeddings, train_captions, one_nn, batch_size=1024)\n",
    "    val_eval_matrix = evaluate(val_captions, predicted_reports, batch_size=12)\n",
    "    val_eval_matrix.to_csv(f'results/val_results_{project_dim}_{seed}.csv', index=False)\n",
    "\n",
    "    predicted_reports = predict(test_image_embeddings, train_captions, one_nn, batch_size=1024)\n",
    "    test_eval_matrix = evaluate(test_captions, predicted_reports, batch_size=12)\n",
    "    test_eval_matrix.to_csv(f'results/test_results_{project_dim}_{seed}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e2e_benchmark(seed, project_dim):\n",
    "    \"\"\"\n",
    "    Perform vector acquisition, 1-NN, and evaluate on val and test set, and save results into files\n",
    "    \"\"\"\n",
    "\n",
    "    # Get vector\n",
    "    train_image_embeddings, train_captions, val_image_embeddings, val_captions, test_image_embeddings, test_captions = get_vectors(seed, project_dim)\n",
    "\n",
    "    # Fit projected vectors into knn\n",
    "    indices = [*range(train_image_embeddings.shape[0])]\n",
    "    one_nn = KNeighborsClassifier(n_neighbors=1)\n",
    "    one_nn.fit(train_image_embeddings, indices)\n",
    "\n",
    "    # Evaluate\n",
    "    evaluate_all(one_nn, train_captions, val_image_embeddings, val_captions, test_image_embeddings, test_captions, seed, project_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random projecting with SEED=1000, RANDOM_PROJECT_DIM=128\n",
      "Projecting train vectors...\n",
      "n_split=17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [02:51<00:00, 10.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(267838, 128)\n",
      "(267838, 402)\n",
      "Projecting val & test vectors...\n",
      "n_split=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2085, 128)\n",
      "(2085, 402)\n",
      "n_split=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3653, 128)\n",
      "(3653, 402)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:07<00:00,  2.46s/it]\n",
      "100%|██████████| 174/174 [00:44<00:00,  3.90it/s]\n",
      "100%|██████████| 174/174 [00:51<00:00,  3.36it/s]\n",
      "100%|██████████| 4/4 [00:12<00:00,  3.11s/it]\n",
      "100%|██████████| 305/305 [01:36<00:00,  3.17it/s]\n",
      "100%|██████████| 305/305 [01:51<00:00,  2.74it/s]\n"
     ]
    }
   ],
   "source": [
    "e2e_benchmark(seed=1000, project_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random projecting with SEED=3000, RANDOM_PROJECT_DIM=8192\n",
      "Projecting train vectors...\n",
      "n_split=17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [35:07<00:00, 123.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(267838, 8192)\n",
      "(267838, 402)\n",
      "Projecting val & test vectors...\n",
      "n_split=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:41<00:00, 41.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2085, 8192)\n",
      "(2085, 402)\n",
      "n_split=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:01<00:00, 61.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3653, 8192)\n",
      "(3653, 402)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [30:11<00:00, 603.80s/it]\n",
      "100%|██████████| 174/174 [00:50<00:00,  3.45it/s]\n",
      "100%|██████████| 174/174 [00:52<00:00,  3.31it/s]\n",
      "100%|██████████| 4/4 [55:17<00:00, 829.33s/it]\n",
      "100%|██████████| 305/305 [01:38<00:00,  3.11it/s]\n",
      "100%|██████████| 305/305 [01:36<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random projecting with SEED=4000, RANDOM_PROJECT_DIM=8192\n",
      "Projecting train vectors...\n",
      "n_split=17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [33:11<00:00, 117.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(267838, 8192)\n",
      "(267838, 402)\n",
      "Projecting val & test vectors...\n",
      "n_split=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:41<00:00, 41.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2085, 8192)\n",
      "(2085, 402)\n",
      "n_split=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:55<00:00, 55.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3653, 8192)\n",
      "(3653, 402)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [30:07<00:00, 602.44s/it]\n",
      "100%|██████████| 174/174 [00:48<00:00,  3.56it/s]\n",
      "100%|██████████| 174/174 [00:51<00:00,  3.37it/s]\n",
      "100%|██████████| 4/4 [54:34<00:00, 818.54s/it]\n",
      "100%|██████████| 305/305 [01:37<00:00,  3.14it/s]\n",
      "100%|██████████| 305/305 [01:36<00:00,  3.15it/s]\n"
     ]
    }
   ],
   "source": [
    "seeds = [3000, 4000]\n",
    "dims = [8192]\n",
    "\n",
    "for dim in dims:\n",
    "    for seed in seeds:\n",
    "        path_to_check = f'results/val_results_{dim}_{seed}.csv'\n",
    "        exist = os.path.exists(path_to_check)\n",
    "        if not exist:\n",
    "            e2e_benchmark(seed=seed, project_dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_embeddings, train_captions, val_image_embeddings, val_captions, test_image_embeddings, test_captions = get_vectors(0, 2048, load=True)\n",
    "indices = [*range(train_image_embeddings.shape[0])]\n",
    "one_nn = KNeighborsClassifier(n_neighbors=1)\n",
    "one_nn.fit(train_image_embeddings, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:51<00:00, 12.79s/it]\n"
     ]
    }
   ],
   "source": [
    "test_predicted_reports = predict(test_image_embeddings, train_captions, one_nn, batch_size=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chexperify(captions, batch_size):\n",
    "    df = []\n",
    "    data_loader = DataLoader(\n",
    "        captions, \n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    for batch in tqdm(data_loader):\n",
    "        labels = chexpert(batch, tokenizer)\n",
    "        df.append(labels)\n",
    "\n",
    "\n",
    "    df = pd.concat(df).reset_index(drop=True)\n",
    "    df['captions'] = tokenizer.decode(captions)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [01:57<00:00,  2.60it/s]\n"
     ]
    }
   ],
   "source": [
    "true_df = chexperify(test_captions, batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>captions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>lateral view somewhat limited due to overlying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>lateral view somewhat limited due to overlying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>frontal and lateral radiographs of the chest a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>frontal and lateral radiographs of the chest a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>frontal and lateral radiographs of the chest a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3648</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>one of the right chest tubes appears to have b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>one of the right chest tubes appears to have b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>one of the right chest tubes appears to have b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pa and lateral chest views were obtained with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3652</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pa and lateral chest views were obtained with ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3653 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Enlarged Cardiomediastinum  Cardiomegaly  Lung Opacity  Lung Lesion  \\\n",
       "0                            0.0           0.0           0.0          0.0   \n",
       "1                            0.0           0.0           0.0          0.0   \n",
       "2                            0.0           0.0           0.0          0.0   \n",
       "3                            0.0           0.0           0.0          0.0   \n",
       "4                            0.0           0.0           0.0          0.0   \n",
       "...                          ...           ...           ...          ...   \n",
       "3648                         0.0           0.0           0.0          0.0   \n",
       "3649                         0.0           0.0           0.0          0.0   \n",
       "3650                         0.0           0.0           0.0          0.0   \n",
       "3651                         0.0           0.0           0.0          0.0   \n",
       "3652                         0.0           0.0           0.0          0.0   \n",
       "\n",
       "      Edema  Consolidation  Pneumonia  Atelectasis  Pneumothorax  \\\n",
       "0       0.0            0.0        0.0          0.0           0.0   \n",
       "1       0.0            0.0        0.0          0.0           0.0   \n",
       "2       0.0            0.0        0.0          0.0           0.0   \n",
       "3       0.0            0.0        0.0          0.0           0.0   \n",
       "4       0.0            0.0        0.0          0.0           0.0   \n",
       "...     ...            ...        ...          ...           ...   \n",
       "3648    0.0            0.0        0.0          0.0           1.0   \n",
       "3649    0.0            0.0        0.0          0.0           1.0   \n",
       "3650    0.0            0.0        0.0          0.0           1.0   \n",
       "3651    0.0            0.0        0.0          0.0           1.0   \n",
       "3652    0.0            0.0        0.0          0.0           1.0   \n",
       "\n",
       "      Pleural Effusion  Pleural Other  Fracture  Support Devices  No Finding  \\\n",
       "0                  0.0            0.0       0.0              0.0         0.0   \n",
       "1                  0.0            0.0       0.0              0.0         0.0   \n",
       "2                  0.0            0.0       0.0              0.0         1.0   \n",
       "3                  0.0            0.0       0.0              0.0         1.0   \n",
       "4                  0.0            0.0       0.0              0.0         1.0   \n",
       "...                ...            ...       ...              ...         ...   \n",
       "3648               0.0            0.0       1.0              1.0         0.0   \n",
       "3649               0.0            0.0       1.0              1.0         0.0   \n",
       "3650               0.0            0.0       1.0              1.0         0.0   \n",
       "3651               0.0            0.0       0.0              1.0         0.0   \n",
       "3652               0.0            0.0       0.0              1.0         0.0   \n",
       "\n",
       "                                               captions  \n",
       "0     lateral view somewhat limited due to overlying...  \n",
       "1     lateral view somewhat limited due to overlying...  \n",
       "2     frontal and lateral radiographs of the chest a...  \n",
       "3     frontal and lateral radiographs of the chest a...  \n",
       "4     frontal and lateral radiographs of the chest a...  \n",
       "...                                                 ...  \n",
       "3648  one of the right chest tubes appears to have b...  \n",
       "3649  one of the right chest tubes appears to have b...  \n",
       "3650  one of the right chest tubes appears to have b...  \n",
       "3651  pa and lateral chest views were obtained with ...  \n",
       "3652  pa and lateral chest views were obtained with ...  \n",
       "\n",
       "[3653 rows x 15 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [01:33<00:00,  3.25it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_df = chexperify(test_predicted_reports, batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>captions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bibasilar atelectasis is similar to appearance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>there is no change . relatively low lung volum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>mild hyperinflation and flattened diaphragms i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>there is a small nodular opacity in the left l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unchanged appearance of the intact sternotomy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3648</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ap portable chest radiograph obtained . there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tracheostomy is unchanged in position . a righ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a portable frontal chest radiograph demonstrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>increased retrocardiac opacity compared to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3652</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pa and lateral images of the chest demonstrate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3653 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Enlarged Cardiomediastinum  Cardiomegaly  Lung Opacity  Lung Lesion  \\\n",
       "0                            0.0           0.0           0.0          0.0   \n",
       "1                            0.0           0.0           0.0          0.0   \n",
       "2                            0.0           0.0           0.0          0.0   \n",
       "3                            0.0           0.0           0.0          0.0   \n",
       "4                            1.0           1.0           0.0          0.0   \n",
       "...                          ...           ...           ...          ...   \n",
       "3648                         0.0           0.0           0.0          0.0   \n",
       "3649                         1.0           1.0           1.0          1.0   \n",
       "3650                         0.0           0.0           0.0          1.0   \n",
       "3651                         0.0           0.0           1.0          0.0   \n",
       "3652                         0.0           0.0           0.0          0.0   \n",
       "\n",
       "      Edema  Consolidation  Pneumonia  Atelectasis  Pneumothorax  \\\n",
       "0       0.0            0.0        0.0          0.0           0.0   \n",
       "1       0.0            0.0        0.0          0.0           0.0   \n",
       "2       0.0            0.0        1.0          0.0           0.0   \n",
       "3       0.0            0.0        0.0          0.0           0.0   \n",
       "4       0.0            0.0        0.0          0.0           0.0   \n",
       "...     ...            ...        ...          ...           ...   \n",
       "3648    0.0            0.0        0.0          0.0           1.0   \n",
       "3649    1.0            1.0        1.0          1.0           0.0   \n",
       "3650    0.0            0.0        0.0          0.0           1.0   \n",
       "3651    0.0            0.0        1.0          1.0           0.0   \n",
       "3652    0.0            0.0        0.0          0.0           0.0   \n",
       "\n",
       "      Pleural Effusion  Pleural Other  Fracture  Support Devices  No Finding  \\\n",
       "0                  0.0            0.0       1.0              0.0         1.0   \n",
       "1                  0.0            0.0       0.0              0.0         1.0   \n",
       "2                  0.0            1.0       1.0              0.0         1.0   \n",
       "3                  0.0            0.0       0.0              1.0         0.0   \n",
       "4                  0.0            0.0       0.0              1.0         0.0   \n",
       "...                ...            ...       ...              ...         ...   \n",
       "3648               0.0            1.0       1.0              1.0         1.0   \n",
       "3649               1.0            0.0       0.0              1.0         0.0   \n",
       "3650               0.0            0.0       1.0              1.0         0.0   \n",
       "3651               0.0            1.0       1.0              0.0         0.0   \n",
       "3652               0.0            1.0       1.0              0.0         1.0   \n",
       "\n",
       "                                               captions  \n",
       "0     bibasilar atelectasis is similar to appearance...  \n",
       "1     there is no change . relatively low lung volum...  \n",
       "2     mild hyperinflation and flattened diaphragms i...  \n",
       "3     there is a small nodular opacity in the left l...  \n",
       "4     unchanged appearance of the intact sternotomy ...  \n",
       "...                                                 ...  \n",
       "3648  ap portable chest radiograph obtained . there ...  \n",
       "3649  tracheostomy is unchanged in position . a righ...  \n",
       "3650  a portable frontal chest radiograph demonstrat...  \n",
       "3651  increased retrocardiac opacity compared to the...  \n",
       "3652  pa and lateral images of the chest demonstrate...  \n",
       "\n",
       "[3653 rows x 15 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5b2b1eb0b4180dccfbf3e31c6f887b3086317eead5a7f5406a6958b92b74dfc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('research_rl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
