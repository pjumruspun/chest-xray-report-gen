{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2091lines [00:00, 149753.09lines/s]\n",
      "2091lines [00:00, 209685.12lines/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caller: c:\\Users\\darkenstardragon\\Documents\\Work\\chest-xray-report-gen\\text_generation\\pytorch_chexpert.py\n",
      "Creating Chexpert reward module...\n",
      "Using 1 GPUs!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from configs import configs\n",
    "from dataset import ChestXRayCaptionDataset\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from utils import train_transform, evaluate_transform\n",
    "from model import Chexnet\n",
    "from pytorch_tokenizer import create_tokenizer\n",
    "from pytorch_test import evaluation_matrix\n",
    "from pytorch_chexpert import chexpert\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_path = 'weights/pca_mean_full.npy'\n",
    "components_path = 'weights/pca_components_full.npy'\n",
    "LOAD_RANDOM_PROJECTION_DATA = True\n",
    "RANDOM_PROJECT = True\n",
    "RANDOM_PROJECT_DIM = 1024\n",
    "SEED = 0\n",
    "\n",
    "filename = {\n",
    "    'train_x': 'baseline_data/' + configs['mimic_dir'] + f'train_image_embeddings_{RANDOM_PROJECT_DIM}_{SEED}.npy',\n",
    "    'train_y': 'baseline_data/' + configs['mimic_dir'] + f'train_captions_{RANDOM_PROJECT_DIM}_{SEED}.npy',\n",
    "    'val_x': 'baseline_data/' + configs['mimic_dir'] + f'val_image_embeddings_{RANDOM_PROJECT_DIM}_{SEED}.npy',\n",
    "    'val_y': 'baseline_data/' + configs['mimic_dir'] + f'val_captions_{RANDOM_PROJECT_DIM}_{SEED}.npy',\n",
    "    'test_x': 'baseline_data/' + configs['mimic_dir'] + f'test_image_embeddings_{RANDOM_PROJECT_DIM}_{SEED}.npy',\n",
    "    'test_y': 'baseline_data/' + configs['mimic_dir'] + f'test_captions_{RANDOM_PROJECT_DIM}_{SEED}.npy',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2091lines [00:00, 190608.75lines/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from weights/pretrained_encoder/pretrained_enc_epoch_5_2022-03-08_15-43-47.540586.pth.tar\n"
     ]
    }
   ],
   "source": [
    "tokenizer = create_tokenizer()\n",
    "encoder = Chexnet.finetuned()\n",
    "pca_mean = None\n",
    "pca_components = None\n",
    "train_loader = DataLoader(\n",
    "    ChestXRayCaptionDataset('train', transform=train_transform),\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    ChestXRayCaptionDataset('val', transform=evaluate_transform),\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    ChestXRayCaptionDataset('test', transform=evaluate_transform),\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_embeddings(encoder, data_loader):\n",
    "    encoder.eval()\n",
    "    image_embeddings = []\n",
    "    probs = []\n",
    "    captions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (img, caption, _) in enumerate(tqdm(data_loader)):\n",
    "            img = img.cuda()\n",
    "            encoded_img, prob = encoder(img)\n",
    "            image_embeddings.append(encoded_img.cpu())\n",
    "            probs.append(prob.cpu())\n",
    "            captions.append(caption.cpu())\n",
    "\n",
    "    image_embeddings = torch.cat(image_embeddings).reshape(-1, 1024*8*8).numpy()\n",
    "    probs = torch.cat(probs).numpy()\n",
    "    captions = torch.cat(captions).numpy()\n",
    "    return image_embeddings, probs, captions\n",
    "\n",
    "def generate_image_embeddings_random(encoder, data_loader, projection_matrix, project_every=2):\n",
    "    # With random projection\n",
    "    encoder.eval()\n",
    "    image_embeddings = []\n",
    "    captions = []\n",
    "    batch = []\n",
    "    with torch.no_grad():\n",
    "        for i, (img, caption, _) in enumerate(tqdm(data_loader)):\n",
    "            img = img.cuda()\n",
    "            encoded_img, prob = encoder(img)\n",
    "            batch.append(encoded_img.cpu())\n",
    "            captions.append(caption.cpu())\n",
    "            if ((i+1) % project_every) == 0 or (i+1) == len(data_loader):\n",
    "                batch = torch.cat(batch).reshape(-1, 1024*8*8).numpy()\n",
    "                batch = np.matmul(batch, projection_matrix)\n",
    "                image_embeddings.append(batch)\n",
    "                batch = []\n",
    "\n",
    "    image_embeddings = np.vstack(image_embeddings)\n",
    "    captions = torch.cat(captions).numpy()\n",
    "    return image_embeddings, captions\n",
    "\n",
    "def load_pca():\n",
    "    global pca_mean, pca_components\n",
    "    pca_mean = np.load(mean_path)\n",
    "    pca_components = np.load(components_path)\n",
    "\n",
    "def pca_transform(embeddings):\n",
    "    if type(pca_mean) == type(None) or type(pca_components) == type(None):\n",
    "        load_pca()\n",
    "    return np.dot(embeddings - pca_mean, pca_components.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205181, 1024)\n",
      "(205181, 246)\n"
     ]
    }
   ],
   "source": [
    "if RANDOM_PROJECT:\n",
    "    if LOAD_RANDOM_PROJECTION_DATA:\n",
    "        train_image_embeddings = np.load(filename['train_x'])\n",
    "        train_captions = np.load(filename['train_y'])\n",
    "        print(train_image_embeddings.shape)\n",
    "        print(train_captions.shape)\n",
    "    else:\n",
    "        rng = np.random.RandomState(SEED)\n",
    "        # Gaussian random projection\n",
    "        projection_matrix = rng.normal(0.0, 1/RANDOM_PROJECT_DIM, (65536, RANDOM_PROJECT_DIM))\n",
    "        project_every = 256\n",
    "        train_image_embeddings, train_captions = generate_image_embeddings_random(encoder, train_loader, projection_matrix, project_every=project_every)\n",
    "        print(train_image_embeddings.shape)\n",
    "        print(train_captions.shape)\n",
    "        np.save(filename['train_x'], train_image_embeddings)\n",
    "        np.save(filename['train_y'], train_captions)\n",
    "else:\n",
    "    train_image_embeddings, train_probs, train_captions = generate_image_embeddings(encoder, train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca training\n",
    "# if not RANDOM_PROJECT:\n",
    "#     pca = PCA(n_components=1024)\n",
    "#     pca.fit(train_image_embeddings)\n",
    "#     np.save(mean_path, pca.mean_)\n",
    "#     np.save(components_path, pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27358, 1024)\n",
      "(27358, 246)\n",
      "(41037, 1024)\n",
      "(41037, 246)\n"
     ]
    }
   ],
   "source": [
    "if RANDOM_PROJECT:\n",
    "    if LOAD_RANDOM_PROJECTION_DATA:\n",
    "        val_image_embeddings = np.load(filename['val_x'])\n",
    "        val_captions = np.load(filename['val_y'])\n",
    "        test_image_embeddings = np.load(filename['test_x'])\n",
    "        test_captions = np.load(filename['test_y'])\n",
    "        print(val_image_embeddings.shape)\n",
    "        print(val_captions.shape)\n",
    "        print(test_image_embeddings.shape)\n",
    "        print(test_captions.shape)\n",
    "    else:\n",
    "        rng = np.random.RandomState(SEED)\n",
    "        # Gaussian random projection\n",
    "        projection_matrix = rng.normal(0.0, 1/RANDOM_PROJECT_DIM, (65536, RANDOM_PROJECT_DIM))\n",
    "        project_every = 256\n",
    "        val_image_embeddings, val_captions = generate_image_embeddings_random(encoder, val_loader, projection_matrix, project_every=project_every)\n",
    "        print(val_image_embeddings.shape)\n",
    "        print(val_captions.shape)\n",
    "        test_image_embeddings, test_captions = generate_image_embeddings_random(encoder, test_loader, projection_matrix, project_every=project_every)\n",
    "        print(test_image_embeddings.shape)\n",
    "        print(test_captions.shape)\n",
    "        np.save(filename['val_x'], val_image_embeddings)\n",
    "        np.save(filename['val_y'], val_captions)\n",
    "        np.save(filename['test_x'], test_image_embeddings)\n",
    "        np.save(filename['test_y'], test_captions)\n",
    "else:\n",
    "    val_image_embeddings, val_probs, val_captions = generate_image_embeddings(encoder, val_loader)\n",
    "    test_image_embeddings, test_probs, test_captions = generate_image_embeddings(encoder, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not RANDOM_PROJECT:\n",
    "    train_image_embeddings = pca_transform(train_image_embeddings)\n",
    "    val_image_embeddings = pca_transform(val_image_embeddings)\n",
    "    test_image_embeddings = pca_transform(test_image_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit pca transformed into knn\n",
    "indices = [*range(train_image_embeddings.shape[0])]\n",
    "one_nn = KNeighborsClassifier(n_neighbors=1)\n",
    "one_nn.fit(train_image_embeddings, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(embeddings, decode=False, batch_size=64):\n",
    "    captions = []\n",
    "    data_loader = DataLoader(\n",
    "        embeddings,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    for j, batch in enumerate(tqdm(data_loader)):\n",
    "        dists, indices = one_nn.kneighbors(batch)\n",
    "        captions.extend([train_captions[i] for i in indices])\n",
    "    captions = np.array(captions).reshape(embeddings.shape[0], -1)\n",
    "    if decode:\n",
    "        captions = tokenizer.decode(captions)\n",
    "    return captions\n",
    "\n",
    "def evaluate(true_captions, pred_captions, batch_size):\n",
    "    true_df = []\n",
    "    pred_df = []\n",
    "\n",
    "    true_loader = DataLoader(\n",
    "        true_captions, \n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    pred_loader = DataLoader(\n",
    "        pred_captions, \n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    for t in tqdm(true_loader):\n",
    "        labels = chexpert(t, tokenizer)\n",
    "        true_df.append(labels)\n",
    "\n",
    "    for p in tqdm(pred_loader):\n",
    "        labels = chexpert(p, tokenizer)\n",
    "        pred_df.append(labels)\n",
    "    \n",
    "    true_df = pd.concat(true_df).reset_index(drop=True)\n",
    "    pred_df = pd.concat(pred_df).reset_index(drop=True)\n",
    "    return evaluation_matrix(true_df, pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [02:30<00:00,  5.58s/it]\n",
      "100%|██████████| 2280/2280 [05:37<00:00,  6.76it/s]\n",
      "100%|██████████| 2280/2280 [05:25<00:00,  7.01it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted_reports = predict(val_image_embeddings, batch_size=1024)\n",
    "val_eval_matrix = evaluate(val_captions, predicted_reports, batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <td>0.7247</td>\n",
       "      <td>0.6553</td>\n",
       "      <td>0.6883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <td>0.6668</td>\n",
       "      <td>0.5996</td>\n",
       "      <td>0.6314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lung Opacity</th>\n",
       "      <td>0.7508</td>\n",
       "      <td>0.6905</td>\n",
       "      <td>0.7194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lung Lesion</th>\n",
       "      <td>0.2947</td>\n",
       "      <td>0.3424</td>\n",
       "      <td>0.3167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edema</th>\n",
       "      <td>0.6026</td>\n",
       "      <td>0.5572</td>\n",
       "      <td>0.5790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consolidation</th>\n",
       "      <td>0.6255</td>\n",
       "      <td>0.6054</td>\n",
       "      <td>0.6153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pneumonia</th>\n",
       "      <td>0.4418</td>\n",
       "      <td>0.4656</td>\n",
       "      <td>0.4534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atelectasis</th>\n",
       "      <td>0.6458</td>\n",
       "      <td>0.5931</td>\n",
       "      <td>0.6183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pneumothorax</th>\n",
       "      <td>0.2180</td>\n",
       "      <td>0.2429</td>\n",
       "      <td>0.2298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <td>0.6297</td>\n",
       "      <td>0.5805</td>\n",
       "      <td>0.6041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pleural Other</th>\n",
       "      <td>0.4265</td>\n",
       "      <td>0.4342</td>\n",
       "      <td>0.4303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fracture</th>\n",
       "      <td>0.5497</td>\n",
       "      <td>0.5270</td>\n",
       "      <td>0.5381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Devices</th>\n",
       "      <td>0.6493</td>\n",
       "      <td>0.7152</td>\n",
       "      <td>0.6806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Finding</th>\n",
       "      <td>0.8204</td>\n",
       "      <td>0.8443</td>\n",
       "      <td>0.8322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macro</th>\n",
       "      <td>0.5747</td>\n",
       "      <td>0.5609</td>\n",
       "      <td>0.5669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro</th>\n",
       "      <td>0.6449</td>\n",
       "      <td>0.6264</td>\n",
       "      <td>0.6355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                     Recall  Precision      F1\n",
       "Enlarged Cardiomediastinum  0.7247     0.6553  0.6883\n",
       "Cardiomegaly                0.6668     0.5996  0.6314\n",
       "Lung Opacity                0.7508     0.6905  0.7194\n",
       "Lung Lesion                 0.2947     0.3424  0.3167\n",
       "Edema                       0.6026     0.5572  0.5790\n",
       "Consolidation               0.6255     0.6054  0.6153\n",
       "Pneumonia                   0.4418     0.4656  0.4534\n",
       "Atelectasis                 0.6458     0.5931  0.6183\n",
       "Pneumothorax                0.2180     0.2429  0.2298\n",
       "Pleural Effusion            0.6297     0.5805  0.6041\n",
       "Pleural Other               0.4265     0.4342  0.4303\n",
       "Fracture                    0.5497     0.5270  0.5381\n",
       "Support Devices             0.6493     0.7152  0.6806\n",
       "No Finding                  0.8204     0.8443  0.8322\n",
       "Macro                       0.5747     0.5609  0.5669\n",
       "Micro                       0.6449     0.6264  0.6355"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_eval_matrix.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 642/642 [08:14<00:00,  1.30it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "evaluate() missing 1 required positional argument: 'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\darkenstardragon\\Documents\\Work\\chest-xray-report-gen\\text_generation\\baseline.ipynb Cell 14'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/darkenstardragon/Documents/Work/chest-xray-report-gen/text_generation/baseline.ipynb#ch0000014?line=0'>1</a>\u001b[0m predicted_reports \u001b[39m=\u001b[39m predict(test_image_embeddings)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/darkenstardragon/Documents/Work/chest-xray-report-gen/text_generation/baseline.ipynb#ch0000014?line=1'>2</a>\u001b[0m test_eval_matrix \u001b[39m=\u001b[39m evaluate(test_captions, predicted_reports)\n",
      "\u001b[1;31mTypeError\u001b[0m: evaluate() missing 1 required positional argument: 'batch_size'"
     ]
    }
   ],
   "source": [
    "predicted_reports = predict(test_image_embeddings)\n",
    "test_eval_matrix = evaluate(test_captions, predicted_reports, batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3420/3420 [08:12<00:00,  6.94it/s]\n",
      "100%|██████████| 3420/3420 [08:23<00:00,  6.79it/s]\n"
     ]
    }
   ],
   "source": [
    "test_eval_matrix = evaluate(test_captions, predicted_reports, batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <td>0.7283</td>\n",
       "      <td>0.6613</td>\n",
       "      <td>0.6932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <td>0.6675</td>\n",
       "      <td>0.6090</td>\n",
       "      <td>0.6369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lung Opacity</th>\n",
       "      <td>0.7548</td>\n",
       "      <td>0.6915</td>\n",
       "      <td>0.7218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lung Lesion</th>\n",
       "      <td>0.3034</td>\n",
       "      <td>0.3461</td>\n",
       "      <td>0.3234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edema</th>\n",
       "      <td>0.6008</td>\n",
       "      <td>0.5565</td>\n",
       "      <td>0.5778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consolidation</th>\n",
       "      <td>0.6302</td>\n",
       "      <td>0.6059</td>\n",
       "      <td>0.6178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pneumonia</th>\n",
       "      <td>0.4529</td>\n",
       "      <td>0.4659</td>\n",
       "      <td>0.4593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atelectasis</th>\n",
       "      <td>0.6590</td>\n",
       "      <td>0.6060</td>\n",
       "      <td>0.6314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pneumothorax</th>\n",
       "      <td>0.2444</td>\n",
       "      <td>0.2675</td>\n",
       "      <td>0.2555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <td>0.6448</td>\n",
       "      <td>0.6047</td>\n",
       "      <td>0.6241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pleural Other</th>\n",
       "      <td>0.4205</td>\n",
       "      <td>0.4328</td>\n",
       "      <td>0.4265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fracture</th>\n",
       "      <td>0.5490</td>\n",
       "      <td>0.5366</td>\n",
       "      <td>0.5427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Devices</th>\n",
       "      <td>0.6445</td>\n",
       "      <td>0.7105</td>\n",
       "      <td>0.6759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Finding</th>\n",
       "      <td>0.8196</td>\n",
       "      <td>0.8449</td>\n",
       "      <td>0.8321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macro</th>\n",
       "      <td>0.5800</td>\n",
       "      <td>0.5671</td>\n",
       "      <td>0.5727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro</th>\n",
       "      <td>0.6480</td>\n",
       "      <td>0.6308</td>\n",
       "      <td>0.6393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                     Recall  Precision      F1\n",
       "Enlarged Cardiomediastinum  0.7283     0.6613  0.6932\n",
       "Cardiomegaly                0.6675     0.6090  0.6369\n",
       "Lung Opacity                0.7548     0.6915  0.7218\n",
       "Lung Lesion                 0.3034     0.3461  0.3234\n",
       "Edema                       0.6008     0.5565  0.5778\n",
       "Consolidation               0.6302     0.6059  0.6178\n",
       "Pneumonia                   0.4529     0.4659  0.4593\n",
       "Atelectasis                 0.6590     0.6060  0.6314\n",
       "Pneumothorax                0.2444     0.2675  0.2555\n",
       "Pleural Effusion            0.6448     0.6047  0.6241\n",
       "Pleural Other               0.4205     0.4328  0.4265\n",
       "Fracture                    0.5490     0.5366  0.5427\n",
       "Support Devices             0.6445     0.7105  0.6759\n",
       "No Finding                  0.8196     0.8449  0.8321\n",
       "Macro                       0.5800     0.5671  0.5727\n",
       "Micro                       0.6480     0.6308  0.6393"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eval_matrix.round(4)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5b2b1eb0b4180dccfbf3e31c6f887b3086317eead5a7f5406a6958b92b74dfc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('research_rl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
