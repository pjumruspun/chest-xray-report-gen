{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torchvision.models import vgg19, densenet121\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Fix kernel dying error on matplotlib\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the ImageNet transformation\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)), \n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "# define a 1 image dataset\n",
    "dataset = datasets.ImageFolder(root='gradcam_data/', transform=transform)\n",
    "\n",
    "# define the dataloader to load that single image\n",
    "dataloader = data.DataLoader(dataset=dataset, shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "        \n",
    "        # get the pretrained VGG19 network\n",
    "        self.vgg = vgg19(pretrained=True)\n",
    "        \n",
    "        # disect the network to access its last convolutional layer\n",
    "        self.features_conv = self.vgg.features[:36]\n",
    "        \n",
    "        # get the max pool of the features stem\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        \n",
    "        # get the classifier of the vgg19\n",
    "        self.classifier = self.vgg.classifier\n",
    "        \n",
    "        # placeholder for the gradients\n",
    "        self.gradients = None\n",
    "    \n",
    "    # hook for the gradients of the activations\n",
    "    def activations_hook(self, grad):\n",
    "        self.gradients = grad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features_conv(x)\n",
    "        \n",
    "        # register the hook\n",
    "        h = x.register_hook(self.activations_hook)\n",
    "        \n",
    "        # apply the remaining pooling\n",
    "        x = self.max_pool(x)\n",
    "        x = x.view((1, -1))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    # method for the gradient extraction\n",
    "    def get_activations_gradient(self):\n",
    "        return self.gradients\n",
    "    \n",
    "    # method for the activation exctraction\n",
    "    def get_activations(self, x):\n",
    "        return self.features_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the VGG model\n",
    "vgg = VGG()\n",
    "\n",
    "# set the evaluation mode\n",
    "vgg.eval()\n",
    "\n",
    "# get the image from the dataloader\n",
    "img, _ = next(iter(dataloader))\n",
    "\n",
    "# get the most likely prediction of the model\n",
    "pred = vgg(img).argmax(dim=1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([491])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1bf1f815790>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the gradient of the output with respect to the parameters of the model\n",
    "vgg(img)[:, pred].backward()\n",
    "\n",
    "# pull the gradients out of the model\n",
    "gradients = vgg.get_activations_gradient()\n",
    "\n",
    "# pool the gradients across the channels\n",
    "pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "# get the activations of the last convolutional layer\n",
    "activations = vgg.get_activations(img).detach()\n",
    "\n",
    "# weight the channels by corresponding gradients\n",
    "for i in range(512):\n",
    "    activations[:, i, :, :] *= pooled_gradients[i]\n",
    "    \n",
    "# average the channels of the activations\n",
    "heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "\n",
    "# relu on top of the heatmap\n",
    "# expression (2) in https://arxiv.org/pdf/1610.02391.pdf\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "\n",
    "# normalize the heatmap\n",
    "heatmap /= torch.max(heatmap)\n",
    "\n",
    "# draw the heatmap\n",
    "plt.matshow(heatmap.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread('./gradcam_data/Elephant/1_oRpjlGC3sUy5yQJtpwclwg.jpeg')\n",
    "heatmap = cv2.resize(heatmap.numpy(), (img.shape[1], img.shape[0]))\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "superimposed_img = heatmap * 0.4 + img\n",
    "cv2.imwrite('./map.jpg', superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet, self).__init__()\n",
    "        \n",
    "        # get the pretrained DenseNet201 network\n",
    "        self.densenet = densenet121(pretrained=True)\n",
    "        \n",
    "        # disect the network to access its last convolutional layer\n",
    "        self.features_conv = self.densenet.features\n",
    "        \n",
    "        # add the average global pool\n",
    "        self.global_avg_pool = nn.AvgPool2d(kernel_size=7, stride=1)\n",
    "        \n",
    "        # get the classifier of the vgg19\n",
    "        self.classifier = self.densenet.classifier\n",
    "        \n",
    "        # placeholder for the gradients\n",
    "        self.gradients = None\n",
    "    \n",
    "    # hook for the gradients of the activations\n",
    "    def activations_hook(self, grad):\n",
    "        self.gradients = grad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features_conv(x)\n",
    "        \n",
    "        # register the hook\n",
    "        h = x.register_hook(self.activations_hook)\n",
    "        \n",
    "        # don't forget the pooling\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.view((1, 1024))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    def get_activations_gradient(self):\n",
    "        return self.gradients\n",
    "    \n",
    "    def get_activations(self, x):\n",
    "        return self.features_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([981])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the VGG model\n",
    "densenet = DenseNet()\n",
    "\n",
    "# set the evaluation mode\n",
    "densenet.eval()\n",
    "\n",
    "# get the image from the dataloader\n",
    "img, _ = next(iter(dataloader))\n",
    "\n",
    "# get the most likely prediction of the model\n",
    "pred = densenet(img).argmax(dim=1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1bf215f7940>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the gradient of the output with respect to the parameters of the model\n",
    "densenet(img)[:, pred].backward()\n",
    "\n",
    "# pull the gradients out of the model\n",
    "gradients = densenet.get_activations_gradient()\n",
    "\n",
    "# pool the gradients across the channels\n",
    "pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "# get the activations of the last convolutional layer\n",
    "activations = densenet.get_activations(img).detach()\n",
    "\n",
    "# weight the channels by corresponding gradients\n",
    "for i in range(512):\n",
    "    activations[:, i, :, :] *= pooled_gradients[i]\n",
    "    \n",
    "# average the channels of the activations\n",
    "heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "\n",
    "# relu on top of the heatmap\n",
    "# expression (2) in https://arxiv.org/pdf/1610.02391.pdf\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "\n",
    "# normalize the heatmap\n",
    "heatmap /= torch.max(heatmap)\n",
    "\n",
    "# draw the heatmap\n",
    "plt.matshow(heatmap.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread('./gradcam_data/Elephant/1_oRpjlGC3sUy5yQJtpwclwg.jpeg')\n",
    "heatmap = cv2.resize(heatmap.numpy(), (img.shape[1], img.shape[0]))\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "superimposed_img = heatmap * 0.4 + img\n",
    "cv2.imwrite('./map.jpg', superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[296. , 215. , 196. ],\n",
       "        [296. , 215. , 196. ],\n",
       "        [296. , 215. , 196. ],\n",
       "        ...,\n",
       "        [293.6, 201. , 188. ],\n",
       "        [293.6, 201. , 188. ],\n",
       "        [293.6, 201. , 188. ]],\n",
       "\n",
       "       [[296. , 215. , 196. ],\n",
       "        [296. , 215. , 196. ],\n",
       "        [297. , 216. , 197. ],\n",
       "        ...,\n",
       "        [293.6, 201. , 188. ],\n",
       "        [293.6, 201. , 188. ],\n",
       "        [293.6, 201. , 188. ]],\n",
       "\n",
       "       [[297. , 216. , 197. ],\n",
       "        [297. , 216. , 197. ],\n",
       "        [297. , 216. , 197. ],\n",
       "        ...,\n",
       "        [293.6, 201. , 188. ],\n",
       "        [293.6, 201. , 188. ],\n",
       "        [293.6, 201. , 188. ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[126. , 112. , 102. ],\n",
       "        [133. , 121. , 111. ],\n",
       "        [161. , 151. , 138. ],\n",
       "        ...,\n",
       "        [114. ,  91. ,  84. ],\n",
       "        [117. ,  95. ,  88. ],\n",
       "        [108. ,  85. ,  80. ]],\n",
       "\n",
       "       [[127. , 115. , 105. ],\n",
       "        [145. , 134. , 124. ],\n",
       "        [157. , 149. , 136. ],\n",
       "        ...,\n",
       "        [121. ,  97. ,  92. ],\n",
       "        [116. ,  92. ,  87. ],\n",
       "        [120. ,  96. ,  91. ]],\n",
       "\n",
       "       [[129. , 117. , 107. ],\n",
       "        [137. , 126. , 116. ],\n",
       "        [139. , 131. , 118. ],\n",
       "        ...,\n",
       "        [128. , 104. ,  99. ],\n",
       "        [124. , 100. ,  95. ],\n",
       "        [145. , 121. , 116. ]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "superimposed_img"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5b2b1eb0b4180dccfbf3e31c6f887b3086317eead5a7f5406a6958b92b74dfc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('research_rl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
