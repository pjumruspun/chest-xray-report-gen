{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 2/17 [00:25<03:08, 12.59s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n"
     ]
    }
   ],
   "source": [
    "def read_npy_files_as_matrix(data_split):\n",
    "    \"\"\"\n",
    "    Data must be in ./mimic_cxr/raw_embeddings\n",
    "    \"\"\"\n",
    "    data_path = 'mimic_cxr/raw_embeddings/' + data_split + '/'\n",
    "    if data_split == 'train':\n",
    "        n_split = 17\n",
    "    else:\n",
    "        n_split = 1\n",
    "\n",
    "    image_embeddings = []\n",
    "    captions = []\n",
    "    \n",
    "    for file_index in tqdm(range(n_split)):\n",
    "        feat_maps = np.load(data_path + 'feature_maps_' + str(file_index) + '.npy')[:500]\n",
    "        caps = np.load(data_path + 'captions_' + str(file_index) + '.npy')[:500]\n",
    "        image_embeddings.append(feat_maps)\n",
    "        captions.append(caps)\n",
    "        if file_index == 2:\n",
    "            break\n",
    "    \n",
    "    return np.vstack(image_embeddings), np.vstack(captions)\n",
    "\n",
    "train_image_embeddings, train_captions = read_npy_files_as_matrix('train')\n",
    "val_image_embeddings, _ = read_npy_files_as_matrix('val')\n",
    "test_image_embeddings, _ = read_npy_files_as_matrix('test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = [*range(train_image_embeddings.shape[0])]\n",
    "one_nn = KNeighborsClassifier(n_neighbors=1)\n",
    "one_nn.fit(train_image_embeddings, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 65536)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 65536)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:00<00:06,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption size: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [00:01<00:04,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption size: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [00:02<00:03,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption size: 192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [00:02<00:02,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption size: 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [00:03<00:02,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption size: 320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [00:04<00:01,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption size: 384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [00:04<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption size: 448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption size: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def predict(embeddings, train_captions, one_nn, batch_size=64):\n",
    "    captions = []\n",
    "    total_len = embeddings.shape[0]\n",
    "    data_loader = np.array_split(embeddings, range(batch_size, total_len, batch_size))\n",
    "\n",
    "    for j, batch in enumerate(tqdm(data_loader)):\n",
    "        dists, indices = one_nn.kneighbors(batch)\n",
    "        captions.extend([train_captions[i] for i in indices])\n",
    "        print(f\"caption size: {len(captions)}\")\n",
    "    captions = np.array(captions).reshape(embeddings.shape[0], -1)\n",
    "\n",
    "    return captions\n",
    "\n",
    "predicted_val_captions = predict(val_image_embeddings, train_captions, one_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 402)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_captions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 65536)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_image_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 402)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_val_captions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   4, 1140,   75, ...,    1,    1,    1],\n",
       "       [   4, 1370, 1003, ...,    1,    1,    1],\n",
       "       [   4,  774,   75, ...,    1,    1,    1],\n",
       "       ...,\n",
       "       [   4, 1896,  820, ...,    1,    1,    1],\n",
       "       [   4,   96,    0, ...,    1,    1,    1],\n",
       "       [   4, 1896,  820, ...,    1,    1,    1]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_val_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blas_mkl_info:\n",
      "  NOT AVAILABLE\n",
      "blis_info:\n",
      "  NOT AVAILABLE\n",
      "openblas_info:\n",
      "    library_dirs = ['D:\\\\a\\\\1\\\\s\\\\numpy\\\\build\\\\openblas_info']\n",
      "    libraries = ['openblas_info']\n",
      "    language = f77\n",
      "    define_macros = [('HAVE_CBLAS', None)]\n",
      "blas_opt_info:\n",
      "    library_dirs = ['D:\\\\a\\\\1\\\\s\\\\numpy\\\\build\\\\openblas_info']\n",
      "    libraries = ['openblas_info']\n",
      "    language = f77\n",
      "    define_macros = [('HAVE_CBLAS', None)]\n",
      "lapack_mkl_info:\n",
      "  NOT AVAILABLE\n",
      "openblas_lapack_info:\n",
      "    library_dirs = ['D:\\\\a\\\\1\\\\s\\\\numpy\\\\build\\\\openblas_lapack_info']\n",
      "    libraries = ['openblas_lapack_info']\n",
      "    language = f77\n",
      "    define_macros = [('HAVE_CBLAS', None)]\n",
      "lapack_opt_info:\n",
      "    library_dirs = ['D:\\\\a\\\\1\\\\s\\\\numpy\\\\build\\\\openblas_lapack_info']\n",
      "    libraries = ['openblas_lapack_info']\n",
      "    language = f77\n",
      "    define_macros = [('HAVE_CBLAS', None)]\n"
     ]
    }
   ],
   "source": [
    "np.__config__.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "os.environ['OPENBLAS_NUM_THREADS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'MKL_NUM_THREADS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [35]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m os\u001b[39m.\u001b[39;49menviron[\u001b[39m'\u001b[39;49m\u001b[39mMKL_NUM_THREADS\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\research_rl\\lib\\os.py:675\u001b[0m, in \u001b[0;36m_Environ.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/darkenstardragon/miniconda3/envs/research_rl/lib/os.py?line=671'>672</a>\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencodekey(key)]\n\u001b[0;32m    <a href='file:///c%3A/Users/darkenstardragon/miniconda3/envs/research_rl/lib/os.py?line=672'>673</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/darkenstardragon/miniconda3/envs/research_rl/lib/os.py?line=673'>674</a>\u001b[0m     \u001b[39m# raise KeyError with the original key value\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/darkenstardragon/miniconda3/envs/research_rl/lib/os.py?line=674'>675</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/darkenstardragon/miniconda3/envs/research_rl/lib/os.py?line=675'>676</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecodevalue(value)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'MKL_NUM_THREADS'"
     ]
    }
   ],
   "source": [
    "os.environ['MKL_NUM_THREADS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.62408487 0.8459755  0.42735158]\n",
      " [0.87521632 0.86722164 0.11315083]\n",
      " [0.29878248 0.23107984 0.82366781]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]]\n",
      "[[0.62408487 0.8459755  0.42735158]\n",
      " [0.87521632 0.86722164 0.11315083]\n",
      " [0.29878248 0.23107984 0.82366781]\n",
      " [0.11801006 0.79136219 0.18433709]\n",
      " [0.81919197 0.01698527 0.89859927]\n",
      " [0.3075785  0.21464877 0.00350434]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]]\n",
      "[[0.62408487 0.8459755  0.42735158]\n",
      " [0.87521632 0.86722164 0.11315083]\n",
      " [0.29878248 0.23107984 0.82366781]\n",
      " [0.11801006 0.79136219 0.18433709]\n",
      " [0.81919197 0.01698527 0.89859927]\n",
      " [0.3075785  0.21464877 0.00350434]\n",
      " [0.38713637 0.22149694 0.19068075]\n",
      " [0.39688697 0.85467192 0.69495606]]\n"
     ]
    }
   ],
   "source": [
    "arr = np.zeros((8, 3))\n",
    "start = 0\n",
    "for i in range(3):\n",
    "    new_arr = np.random.rand(2 if i == 2 else 3, 3)\n",
    "    stop = start + new_arr.shape[0]\n",
    "    arr[start:stop,:] = new_arr\n",
    "    print(arr)\n",
    "    start = stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   4, 1140,   75, ...,    1,    1,    1],\n",
       "       [   4, 1370, 1003, ...,    1,    1,    1],\n",
       "       [   4,  774,   75, ...,    1,    1,    1],\n",
       "       ...,\n",
       "       [   4, 1896,  820, ...,    1,    1,    1],\n",
       "       [   4,   96,    0, ...,    1,    1,    1],\n",
       "       [   4, 1896,  820, ...,    1,    1,    1]], dtype=int16)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.load('predicted_val_captions.npy'), dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "type(np.load('mimic_cxr/raw_embeddings/val/feature_maps_0.npy')[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.zeros((1), dtype=np.float32)\n",
    "arr[0] = np.load('mimic_cxr/raw_embeddings/val/feature_maps_0.npy')[0][0]\n",
    "type(arr[0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5b2b1eb0b4180dccfbf3e31c6f887b3086317eead5a7f5406a6958b92b74dfc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('research_rl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
